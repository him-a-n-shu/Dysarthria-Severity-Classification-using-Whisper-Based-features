{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10556447,"sourceType":"datasetVersion","datasetId":6531226},{"sourceId":10565829,"sourceType":"datasetVersion","datasetId":6538091},{"sourceId":10572666,"sourceType":"datasetVersion","datasetId":6542459}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport librosa\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\n\n# ------------------ Feature Extraction ------------------\ndef pad_or_truncate(features, target_length):\n    \"\"\"Pad or truncate features to a fixed length.\"\"\"\n    if features.shape[0] < target_length:\n        padding = target_length - features.shape[0]\n        padded_features = np.pad(features, ((0, padding), (0, 0)), mode='constant')\n        return padded_features\n    else:\n        return features[:target_length, :]\n\ndef extract_lp_residual(audio, order=12):\n    \"\"\"Extract Linear Prediction (LP) residual\"\"\"\n    lpc_coeffs = librosa.lpc(audio, order=order)\n    lp_residual = np.convolve(audio, -lpc_coeffs, mode='full')[:len(audio)]\n    lp_residual = np.nan_to_num(lp_residual, nan=0.0, posinf=0.0, neginf=0.0)\n    return lp_residual\n\ndef extract_mgdcc(audio, sr, alpha=0.4, gamma=0.9, num_coeffs=13):\n    \"\"\"Extract Modified Group Delay Cepstral Coefficients (MGDCC)\"\"\"\n    stft = librosa.stft(audio)\n    magnitude = np.abs(stft)\n    phase = np.angle(stft)\n    group_delay = -np.diff(phase, axis=0)\n    modified_gd = group_delay * (magnitude[:-1, :] ** gamma)\n    mgd_cepstral = librosa.feature.mfcc(S=modified_gd, n_mfcc=num_coeffs)\n    return mgd_cepstral.T","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-24T18:02:49.726591Z","iopub.execute_input":"2025-01-24T18:02:49.726902Z","iopub.status.idle":"2025-01-24T18:02:52.822237Z","shell.execute_reply.started":"2025-01-24T18:02:49.726879Z","shell.execute_reply":"2025-01-24T18:02:52.821163Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ------------------ Dataset Loader ------------------\nclass DysarthriaDataset(Dataset):\n    def __init__(self, data_path, severity_mapping, sr=16000, target_length=100):\n        self.data_path = data_path\n        self.severity_mapping = severity_mapping\n        self.sr = sr\n        self.target_length = target_length\n        self.data = []\n        self.labels = []\n\n        severity_to_label = {severity: i for i, severity in enumerate(severity_mapping.keys())}\n\n        for severity, speakers in severity_mapping.items():\n            for speaker in speakers:\n                speaker_path = os.path.join(data_path, speaker)\n                for file in os.listdir(speaker_path):\n                    if file.endswith(\".wav\"):\n                        self.data.append(os.path.join(speaker_path, file))\n                        self.labels.append(severity_to_label[severity])\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        file_path = self.data[idx]\n        label = self.labels[idx]\n        audio, _ = librosa.load(file_path, sr=self.sr)\n        lp_residual = extract_lp_residual(audio)\n        features = extract_mgdcc(lp_residual, self.sr)\n        features = pad_or_truncate(features, self.target_length)\n        features = torch.tensor(features, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n        label = torch.tensor(label, dtype=torch.long)\n        return features, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T18:02:52.823684Z","iopub.execute_input":"2025-01-24T18:02:52.824198Z","iopub.status.idle":"2025-01-24T18:02:52.831838Z","shell.execute_reply.started":"2025-01-24T18:02:52.824162Z","shell.execute_reply":"2025-01-24T18:02:52.830843Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class DysarthriaSeverityCNN(nn.Module):\n    def __init__(self, num_classes=4):\n        super(DysarthriaSeverityCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.fc1_input_size = None  # Placeholder for dynamic computation\n        self.fc1 = None\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        \n        # Flatten the output of the convolutional layers\n        x = x.view(x.size(0), -1)\n\n        # Dynamically initialize fc1 if needed\n        if self.fc1 is None:\n            self.fc1_input_size = x.size(1)\n            self.fc1 = nn.Linear(self.fc1_input_size, 128).to(x.device)\n\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)  # Raw logits\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T18:02:57.010260Z","iopub.execute_input":"2025-01-24T18:02:57.010563Z","iopub.status.idle":"2025-01-24T18:02:57.016769Z","shell.execute_reply.started":"2025-01-24T18:02:57.010537Z","shell.execute_reply":"2025-01-24T18:02:57.015875Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def train_model(model, dataloader, criterion, optimizer, device, num_epochs=10):\n    model.train()\n    for epoch in range(num_epochs):\n        epoch_loss = 0\n        correct = 0\n        total = 0\n\n        for inputs, labels in tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n            # Move data to device\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        if (epoch+1)%10 == 0:\n            torch.save(model, f\"model_{epoch+1}.pth\")\n            print(f\"Model saved at {epoch+1+25}\")\n        accuracy = 100 * correct / total\n        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(dataloader):.4f}, Accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T18:02:59.397522Z","iopub.execute_input":"2025-01-24T18:02:59.397851Z","iopub.status.idle":"2025-01-24T18:02:59.403787Z","shell.execute_reply.started":"2025-01-24T18:02:59.397823Z","shell.execute_reply":"2025-01-24T18:02:59.402902Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from torch.utils.data import random_split\n\nseverity_mapping = {\n    \"HIGH\": [\"M01\", \"M04\", \"M12\", \"F03\"],\n    \"MEDIUM\": [\"F02\", \"M07\", \"M16\"],\n    \"LOW\": [\"F04\", \"M05\", \"M11\"],\n    \"VERY LOW\": [\"F05\", \"M08\", \"M09\", \"M10\", \"M14\"]\n}\n\ndataset_path = \"/kaggle/input/dysarthria-data/noisereduced-uaspeech\"\ndataset = DysarthriaDataset(dataset_path, severity_mapping)\n# Splitting into train and eval sets\ntrain_size = int(0.8 * len(dataset))  # 80% training\neval_size = len(dataset) - train_size  # 20% evaluation\ntrain_dataset, eval_dataset = random_split(dataset, [train_size, eval_size])\n\n# Creating DataLoaders\ntrain_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=6, pin_memory=True)\neval_dataloader = DataLoader(eval_dataset, batch_size=64, shuffle=False, num_workers=6, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T18:03:02.289679Z","iopub.execute_input":"2025-01-24T18:03:02.290033Z","iopub.status.idle":"2025-01-24T18:03:04.268798Z","shell.execute_reply.started":"2025-01-24T18:03:02.290004Z","shell.execute_reply":"2025-01-24T18:03:04.267906Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Make sure the DysarthriaSeverityCNN class is defined in the script\n# Load the entire DataParallel object\ndata_parallel_model = torch.load(\"/kaggle/input/models-dysar/model_70.pth\")\n\n# Extract the actual model from the DataParallel wrapper\nmodel = data_parallel_model.module\n\n# Move the model to the correct device\nmodel = model.to(device)\n\n# Wrap it again with DataParallel if using multiple GPUs\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)\n\n# Check model with dummy input to initialize layers dynamically\ndummy_input = torch.zeros(1, 1, 100, 13).to(device)  # Shape matches input feature maps\nmodel(dummy_input)\n\n# Wrap model in DataParallel if multiple GPUs are available\n# if torch.cuda.device_count() > 1:\n#     print(f\"Using {torch.cuda.device_count()} GPUs!\")\n#     model = nn.DataParallel(model)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T18:14:12.818278Z","iopub.execute_input":"2025-01-24T18:14:12.818622Z","iopub.status.idle":"2025-01-24T18:14:13.198151Z","shell.execute_reply.started":"2025-01-24T18:14:12.818589Z","shell.execute_reply":"2025-01-24T18:14:13.197440Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-11-fad31d6b6849>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  data_parallel_model = torch.load(\"/kaggle/input/models-dysar/model_70.pth\")\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())  # Should return True\nprint(torch.cuda.current_device())  # Check current GPU device\nprint(torch.cuda.get_device_name(0))  # Get GPU name\nprint(torch.cuda.get_device_name(1))  # Get GPU name","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T09:49:38.056648Z","iopub.execute_input":"2025-01-24T09:49:38.056966Z","iopub.status.idle":"2025-01-24T09:49:38.062805Z","shell.execute_reply.started":"2025-01-24T09:49:38.056938Z","shell.execute_reply":"2025-01-24T09:49:38.061914Z"}},"outputs":[{"name":"stdout","text":"True\n0\nTesla T4\nTesla T4\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"model = model.to(device)  # where device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T18:03:29.357936Z","iopub.execute_input":"2025-01-24T18:03:29.358416Z","iopub.status.idle":"2025-01-24T18:03:29.363130Z","shell.execute_reply.started":"2025-01-24T18:03:29.358386Z","shell.execute_reply":"2025-01-24T18:03:29.362281Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T18:03:30.959607Z","iopub.execute_input":"2025-01-24T18:03:30.960057Z","iopub.status.idle":"2025-01-24T18:03:30.967354Z","shell.execute_reply.started":"2025-01-24T18:03:30.960016Z","shell.execute_reply":"2025-01-24T18:03:30.966464Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model\nprint(\"Starting training...\")\ntrain_model(\n    model=model,\n    dataloader=train_dataloader,\n    criterion=criterion,\n    optimizer=optimizer,\n    device=device,\n    num_epochs=75\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T11:06:50.278934Z","iopub.execute_input":"2025-01-24T11:06:50.279213Z","iopub.status.idle":"2025-01-24T16:23:16.620591Z","shell.execute_reply.started":"2025-01-24T11:06:50.279192Z","shell.execute_reply":"2025-01-24T16:23:16.619566Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/75: 100%|██████████| 921/921 [04:12<00:00,  3.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/75, Loss: 0.5173, Accuracy: 85.16%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/75: 100%|██████████| 921/921 [04:03<00:00,  3.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/75, Loss: 0.3789, Accuracy: 86.52%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/75: 100%|██████████| 921/921 [04:00<00:00,  3.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/75, Loss: 0.3137, Accuracy: 88.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/75: 100%|██████████| 921/921 [04:03<00:00,  3.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/75, Loss: 0.2812, Accuracy: 89.60%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/75: 100%|██████████| 921/921 [04:06<00:00,  3.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/75, Loss: 0.2599, Accuracy: 89.99%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/75: 100%|██████████| 921/921 [04:09<00:00,  3.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/75, Loss: 0.2630, Accuracy: 90.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/75: 100%|██████████| 921/921 [04:10<00:00,  3.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/75, Loss: 0.2292, Accuracy: 91.19%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/75: 100%|██████████| 921/921 [04:06<00:00,  3.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/75, Loss: 0.2147, Accuracy: 91.69%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/75: 100%|██████████| 921/921 [04:07<00:00,  3.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/75, Loss: 0.2074, Accuracy: 91.82%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/75: 100%|██████████| 921/921 [04:09<00:00,  3.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Model saved at 35\nEpoch 10/75, Loss: 0.2003, Accuracy: 92.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/75: 100%|██████████| 921/921 [04:08<00:00,  3.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/75, Loss: 0.1914, Accuracy: 92.38%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/75: 100%|██████████| 921/921 [04:10<00:00,  3.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/75, Loss: 0.1915, Accuracy: 92.41%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/75: 100%|██████████| 921/921 [04:07<00:00,  3.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/75, Loss: 0.1825, Accuracy: 92.78%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/75: 100%|██████████| 921/921 [04:09<00:00,  3.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/75, Loss: 0.1758, Accuracy: 93.07%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/75: 100%|██████████| 921/921 [04:06<00:00,  3.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/75, Loss: 0.1758, Accuracy: 93.12%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/75: 100%|██████████| 921/921 [04:09<00:00,  3.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/75, Loss: 0.1762, Accuracy: 93.11%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/75: 100%|██████████| 921/921 [04:12<00:00,  3.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/75, Loss: 0.2010, Accuracy: 92.38%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/75: 100%|██████████| 921/921 [04:13<00:00,  3.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/75, Loss: 0.1726, Accuracy: 93.18%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/75: 100%|██████████| 921/921 [04:11<00:00,  3.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/75, Loss: 0.1619, Accuracy: 93.65%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/75: 100%|██████████| 921/921 [04:08<00:00,  3.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Model saved at 45\nEpoch 20/75, Loss: 0.1599, Accuracy: 93.67%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/75: 100%|██████████| 921/921 [04:07<00:00,  3.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21/75, Loss: 0.1575, Accuracy: 93.74%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/75: 100%|██████████| 921/921 [04:08<00:00,  3.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22/75, Loss: 0.1567, Accuracy: 93.88%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/75: 100%|██████████| 921/921 [04:14<00:00,  3.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23/75, Loss: 0.1554, Accuracy: 93.82%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/75: 100%|██████████| 921/921 [04:06<00:00,  3.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24/75, Loss: 0.1546, Accuracy: 93.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/75: 100%|██████████| 921/921 [04:06<00:00,  3.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25/75, Loss: 0.1549, Accuracy: 93.91%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/75: 100%|██████████| 921/921 [04:05<00:00,  3.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26/75, Loss: 0.1520, Accuracy: 93.95%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/75: 100%|██████████| 921/921 [04:06<00:00,  3.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27/75, Loss: 0.1507, Accuracy: 94.11%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/75: 100%|██████████| 921/921 [04:13<00:00,  3.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28/75, Loss: 0.1541, Accuracy: 94.09%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/75: 100%|██████████| 921/921 [04:17<00:00,  3.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29/75, Loss: 0.1465, Accuracy: 94.24%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/75: 100%|██████████| 921/921 [04:16<00:00,  3.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Model saved at 55\nEpoch 30/75, Loss: 0.1443, Accuracy: 94.38%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/75: 100%|██████████| 921/921 [04:13<00:00,  3.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31/75, Loss: 0.1431, Accuracy: 94.50%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/75: 100%|██████████| 921/921 [04:11<00:00,  3.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32/75, Loss: 0.1460, Accuracy: 94.28%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/75: 100%|██████████| 921/921 [04:34<00:00,  3.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33/75, Loss: 0.1424, Accuracy: 94.47%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/75: 100%|██████████| 921/921 [04:59<00:00,  3.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34/75, Loss: 0.1384, Accuracy: 94.56%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/75: 100%|██████████| 921/921 [04:05<00:00,  3.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35/75, Loss: 0.1387, Accuracy: 94.55%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/75: 100%|██████████| 921/921 [04:15<00:00,  3.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36/75, Loss: 0.1400, Accuracy: 94.62%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/75: 100%|██████████| 921/921 [04:17<00:00,  3.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37/75, Loss: 0.1398, Accuracy: 94.53%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/75: 100%|██████████| 921/921 [04:19<00:00,  3.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38/75, Loss: 0.1395, Accuracy: 94.52%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/75: 100%|██████████| 921/921 [04:18<00:00,  3.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39/75, Loss: 0.2031, Accuracy: 93.69%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/75: 100%|██████████| 921/921 [04:18<00:00,  3.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Model saved at 65\nEpoch 40/75, Loss: 0.1545, Accuracy: 94.04%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41/75: 100%|██████████| 921/921 [04:21<00:00,  3.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41/75, Loss: 0.1397, Accuracy: 94.57%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42/75: 100%|██████████| 921/921 [04:20<00:00,  3.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42/75, Loss: 0.1343, Accuracy: 94.75%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43/75: 100%|██████████| 921/921 [04:19<00:00,  3.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43/75, Loss: 0.1306, Accuracy: 95.11%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 44/75: 100%|██████████| 921/921 [04:14<00:00,  3.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44/75, Loss: 0.1319, Accuracy: 94.94%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 45/75: 100%|██████████| 921/921 [04:15<00:00,  3.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45/75, Loss: 0.1271, Accuracy: 95.02%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46/75: 100%|██████████| 921/921 [04:10<00:00,  3.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46/75, Loss: 0.1278, Accuracy: 95.19%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 47/75: 100%|██████████| 921/921 [04:07<00:00,  3.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47/75, Loss: 0.1250, Accuracy: 95.22%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 48/75: 100%|██████████| 921/921 [04:12<00:00,  3.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48/75, Loss: 0.1294, Accuracy: 95.02%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 49/75: 100%|██████████| 921/921 [04:07<00:00,  3.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49/75, Loss: 0.1252, Accuracy: 95.30%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 50/75: 100%|██████████| 921/921 [04:10<00:00,  3.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Model saved at 75\nEpoch 50/75, Loss: 0.1273, Accuracy: 95.19%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 51/75: 100%|██████████| 921/921 [04:17<00:00,  3.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 51/75, Loss: 0.1204, Accuracy: 95.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 52/75: 100%|██████████| 921/921 [04:14<00:00,  3.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 52/75, Loss: 0.1224, Accuracy: 95.36%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 53/75: 100%|██████████| 921/921 [04:12<00:00,  3.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 53/75, Loss: 0.1197, Accuracy: 95.43%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 54/75: 100%|██████████| 921/921 [04:10<00:00,  3.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 54/75, Loss: 0.1227, Accuracy: 95.25%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 55/75: 100%|██████████| 921/921 [04:13<00:00,  3.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 55/75, Loss: 0.1180, Accuracy: 95.60%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 56/75: 100%|██████████| 921/921 [04:10<00:00,  3.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 56/75, Loss: 0.1196, Accuracy: 95.52%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 57/75: 100%|██████████| 921/921 [04:14<00:00,  3.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 57/75, Loss: 0.1168, Accuracy: 95.62%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 58/75: 100%|██████████| 921/921 [04:10<00:00,  3.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 58/75, Loss: 0.1179, Accuracy: 95.57%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 59/75: 100%|██████████| 921/921 [04:13<00:00,  3.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 59/75, Loss: 0.1171, Accuracy: 95.56%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 60/75: 100%|██████████| 921/921 [04:13<00:00,  3.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Model saved at 85\nEpoch 60/75, Loss: 0.1199, Accuracy: 95.43%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 61/75: 100%|██████████| 921/921 [04:11<00:00,  3.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 61/75, Loss: 0.1160, Accuracy: 95.64%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 62/75: 100%|██████████| 921/921 [04:16<00:00,  3.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 62/75, Loss: 0.1171, Accuracy: 95.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 63/75: 100%|██████████| 921/921 [04:20<00:00,  3.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 63/75, Loss: 0.1147, Accuracy: 95.76%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 64/75: 100%|██████████| 921/921 [04:18<00:00,  3.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 64/75, Loss: 0.1122, Accuracy: 95.77%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 65/75: 100%|██████████| 921/921 [04:04<00:00,  3.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 65/75, Loss: 0.1157, Accuracy: 95.75%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 66/75: 100%|██████████| 921/921 [04:04<00:00,  3.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 66/75, Loss: 0.1175, Accuracy: 95.53%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 67/75: 100%|██████████| 921/921 [04:04<00:00,  3.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 67/75, Loss: 0.1119, Accuracy: 95.75%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 68/75: 100%|██████████| 921/921 [04:03<00:00,  3.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 68/75, Loss: 0.1102, Accuracy: 95.84%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 69/75: 100%|██████████| 921/921 [04:02<00:00,  3.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 69/75, Loss: 0.1137, Accuracy: 95.75%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 70/75: 100%|██████████| 921/921 [04:23<00:00,  3.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Model saved at 95\nEpoch 70/75, Loss: 0.1107, Accuracy: 95.90%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 71/75: 100%|██████████| 921/921 [04:22<00:00,  3.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 71/75, Loss: 1.1805, Accuracy: 94.79%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 72/75: 100%|██████████| 921/921 [04:23<00:00,  3.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 72/75, Loss: 0.1674, Accuracy: 93.94%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 73/75: 100%|██████████| 921/921 [04:22<00:00,  3.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 73/75, Loss: 0.1397, Accuracy: 94.90%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 74/75: 100%|██████████| 921/921 [04:23<00:00,  3.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 74/75, Loss: 0.1267, Accuracy: 95.34%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 75/75: 100%|██████████| 921/921 [04:24<00:00,  3.49it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 75/75, Loss: 0.1234, Accuracy: 95.38%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"# Save only the state dictionary\ntorch.save(model.module.state_dict(), \"model_50.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T09:37:20.640480Z","iopub.execute_input":"2025-01-24T09:37:20.640730Z","iopub.status.idle":"2025-01-24T09:37:20.680280Z","shell.execute_reply.started":"2025-01-24T09:37:20.640705Z","shell.execute_reply":"2025-01-24T09:37:20.679470Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"import shutil\nfrom IPython.display import HTML","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T09:42:12.617292Z","iopub.execute_input":"2025-01-24T09:42:12.617631Z","iopub.status.idle":"2025-01-24T09:42:12.621093Z","shell.execute_reply.started":"2025-01-24T09:42:12.617604Z","shell.execute_reply":"2025-01-24T09:42:12.620328Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"def create_download_link(filename):\n    shutil.move(filename, f\"/kaggle/working/{filename}\")\n    return HTML(f'<a href=\"{filename}\" download>{filename}</a>')\n\n# Generate the download link for the saved model\ncreate_download_link(\"model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T09:42:40.237229Z","iopub.execute_input":"2025-01-24T09:42:40.237572Z","iopub.status.idle":"2025-01-24T09:42:40.243264Z","shell.execute_reply.started":"2025-01-24T09:42:40.237541Z","shell.execute_reply":"2025-01-24T09:42:40.242597Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<a href=\"model.pth\" download>model.pth</a>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"# Evaluation loop\ndef evaluate_model(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = 100 * correct / total\n    avg_loss = total_loss / len(dataloader)\n    print(f\"Validation Loss: {avg_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n    return avg_loss, accuracy\n\n# Evaluate the model on validation set\nprint(\"Evaluating model...\")\nevaluate_model(model, eval_dataloader, criterion, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T18:14:23.199661Z","iopub.execute_input":"2025-01-24T18:14:23.199999Z","iopub.status.idle":"2025-01-24T18:15:28.441114Z","shell.execute_reply.started":"2025-01-24T18:14:23.199973Z","shell.execute_reply":"2025-01-24T18:15:28.440308Z"}},"outputs":[{"name":"stdout","text":"Evaluating model...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 231/231 [01:05<00:00,  3.54it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.1598, Validation Accuracy: 97.31%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(0.1598398262358702, 97.3057346454021)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}